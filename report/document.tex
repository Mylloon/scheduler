\DocumentMetadata{testphase = {phase-II,sec,toc,graphic,minipage,float,text}}
\documentclass{article}

\usepackage[T1]{fontenc} % encoding
\renewcommand{\familydefault}{\sfdefault} % sans-serif font

% Langages
\usepackage[french]{babel}
\frenchsetup{SmallCapsFigTabCaptions=false}

% Add \extra info to title
\makeatletter
\providecommand{\extra}[1]{
  \apptocmd{\@author}{
    \end{tabular}
    \par\vspace*{0.7em}
    \begin{tabular}[t]{c}
    #1}{}{}
}
\makeatother

% Code integration
\usepackage{minted}
\setminted[c]{autogobble,frame=lines}
\usemintedstyle{emacs}

\def\titleName{Projet : Un ordonnanceur par work stealing}
\def\docTitle{\href{https://www.irif.fr/~jch/enseignement/systeme/projet.pdf}{\titleName}}

\def\anri{Anri Kennel}
\def\authorMail{mailto:anri.kennel@etu.u-paris.fr}
\def\docSubject{Programmation système avancée}
\def\docLocation{Université Paris Cité}

\usepackage[
  pdfauthor={\anri},        % author  metadata
  pdftitle={\titleName},    % title   metadata
  pdfsubject={\docSubject}, % subject metadata
  hidelinks,                % clickable links in table of contents
]{hyperref}

\title{\docTitle}
\author{\href{\authorMail}{\anri}\thanks{\anri : 22302653}}
\extra{\docSubject~$\cdot$ \docLocation}
\date{Année universitaire 2023-2024}

\newcommand{\docref}[1]{\textit{\nameref{#1}}} % italic nameref

% Aliases
\def\coeurs{c\oe{}urs}


\begin{document}
\maketitle
\flushbottom
\tableofcontents
\clearpage

% TODO: Mandelbrot
% TODO: Computer 2

\section{Descriptions}
Description des différents algorithmes implémentés.

\subsection{Séquentiel}
Cette implémentation naïve correspond au mode \texttt{serial}
de \texttt{quicksort.c}. Elle lance les tâches sans threads.

\subsection[Threads sans gestion]{Threads sans gestion}
Cette implémentation correspond à simplement démarrer un nouveau thread
pour chaque nouvelle tâche.

Comme cette implémentation n'ordonnance rien et que le nombre de threads créer
est important.

\subsection{Threads avec pile}\label{desc:th_pile}
Pour cette implémentation, on garde en mémoire une pile,
et on démarre un nombre fixe de threads et à chaque ajout d'une tâche,
on l'empile. Chaque thread récupère la dernière tâche ajoutée à la pile.

\subsubsection{Sélection aléatoire de tâche}
Même fonctionnement que dans l'algorithme de \docref{desc:th_pile}, sauf
qu'au lieu de récupérer la dernière tâche, on récupère une tâche
aléatoire de la pile.

\subsection{Répartition par work-stealing}
\begin{itemize}
  \item Au lieu d'avoir une pile unique, chaque thread à sa propre liste
  \item Chaque tâche est ajouté sur le même thread de sa création.
  \item Quand un thread n'as pas de tâches à faire, il vole une tâche à un autre
        thread, en partant de la fin
\end{itemize}

\section{Statistiques}

\def\mone{\textit{Machine 1}} % fixe
\def\mtwo{\textit{Machine 2}} % portable

\def\bone{\textit{Benchmark quicksort}}
\def\btwo{\textit{Benchmark mandelbrot}}

Chaque implémentation a été testée avec l'optimisation de niveau 2
de \texttt{gcc}, sur 2 machines.

\begin{enumerate}
  \item \textbf{12 \coeurs} pour la \mone.
  \item \textbf{8 \coeurs} pour la \mtwo.
\end{enumerate}

Le programme utilisé pour tester les implémentations sont le quicksort fourni
et une adaptation de mandelbrot fournis dans le TP10.

\subsection{Séquentiel}\label{stats:seq}
\begin{description}
  \item[\bone] \hspace{1em}
        \begin{description}
          \item[\mone] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{0,855 secs}
          \item[\mtwo] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{1,139 secs}
        \end{description}

  \item[\btwo] \hspace{1em}
        \begin{description}
          \item[\mone] Le programme a été lancé \textbf{10 fois}.
                Le temps moyen d'exécution a été de \textbf{3,733 secs}
          \item[\mtwo] Le programme a été lancé \textbf{10 fois}.
                Le temps moyen d'exécution a été de \textbf{6,020 secs}
        \end{description}
\end{description}


Ce programme ne bénéficie pas de toute la puissance de la machine.

\subsection{Threads sans gestion}\label{stats:th_ges}

\begin{description}
  \item[\bone] \hspace{1em}
        \begin{description}
          \item[\mone] Le programme a été lancé \textbf{10 fois}.
                Le temps moyen d'exécution a été de \textbf{35,985 secs}
          \item[\mtwo] Le programme a été lancé \textbf{10 fois}.
                Le temps moyen d'exécution a été de \textbf{18,854 secs}
        \end{description}

  \item[\btwo] \hspace{1em}
        \begin{description}
          \item[\mone] Le programme a été lancé \textbf{10 fois}.
                Le temps moyen d'exécution a été de \textbf{66,078 secs}
          \item[\mtwo] Le programme a été lancé \textbf{10 fois}.
                Le temps moyen d'exécution a été de \textbf{41,060 secs}
        \end{description}
\end{description}

La création des threads pour chaque tâche créer un énorme
goulot d'étranglement qui réduit de grandement les performances.

Le temps d'exécution étant long, nous pouvons voir les threads via la commande
\texttt{top} : \mintinline{bash}|top -Hp $(pgrep ordonnanceur)|.

Pour augmenter les performances, il faut avoir une taille fixe de threads créer,
et donc il faut gérer les tâches et décider de quelle tâche va sur quel thread.

\subsection{Threads avec pile}\label{stats:stack}
\begin{description}
  \item[\bone] \hspace{1em}
        \begin{description}
          \item[\mone] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{0,258 secs}
          \item[\mtwo] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{0,356 secs}
        \end{description}

  \item[\btwo] \hspace{1em}
        \begin{description}
          \item[\mone] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{0,787 secs}
          \item[\mtwo] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{1,858 secs}
        \end{description}
\end{description}

Le lancement de nouveau thread étant limité, les performances
sont grandement améliorées par rapport aux tests de \docref{stats:th_ges}.

Également grâce au fait que désormais on utilise les \coeurs~de notre CPU,
les performances sont aussi améliorées par rapport aux tests de
\docref{stats:seq}.

\subsubsection{Sélection aléatoire de tâche}
\begin{description}
  \item[\bone] \hspace{1em}
        \begin{description}
          \item[\mone] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{0,390 secs}
          \item[\mtwo] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{0,438 secs}
        \end{description}

  \item[\btwo] \hspace{1em}
        \begin{description}
          \item[\mone] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{0,438 secs}
          \item[\mtwo] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{1,887 secs}
        \end{description}
\end{description}

Cette implémentation est identique à \docref{stats:stack}, à l'exception que
l'on récupère une tâche aléatoire de la pile au lieu d'y prendre la dernière
ajouté.

Cette façon de faire réduit les performances.

\subsection{Répartition par work-stealing}
\begin{description}
  \item[\bone] \hspace{1em}
        \begin{description}
          \item[\mone] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{0,229 secs}
          \item[\mtwo] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{0,308 secs}
        \end{description}

  \item[\btwo] \hspace{1em}
        \begin{description}
          \item[\mone] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{0,447 secs}
          \item[\mtwo] Le programme a été lancé \textbf{100 fois}.
                Le temps moyen d'exécution a été de \textbf{1,131 secs}
        \end{description}
\end{description}

Dans cet implémentation, on n'utilises plus une pile mais un deque de tâches.
Cette façon de faire est légèrement meilleur que \docref{desc:th_pile}.

\end{document}
